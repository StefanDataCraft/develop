{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><center><h1 style=\"font-size:2em;color:#2467C0\">Tagesaufgaben 09.01.2023</h1></center>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "1. Erstelle drei DataFrames die jeweils zwei typische Produkte aus dem Supermarkt enthalten fülle die Tabelle mit Stückzahlen der Produkte. Als Index soll jeder DataFrame drei Supermärkte nach folgendem Schema beinhalten:\n",
    "\n",
    "   1. Der erste df hat die Indices Lidl, Netto, Rewe\n",
    "   2. Der zweite df hat die Indices Lidl, Rewe, Aldi\n",
    "   3. Der dritte df hat die Indices Netto, Rewe, Aldi\n",
    "\n",
    "Füge die drei DataFrames anschließend zusammen, sodass du folgenden Output erhälst (die Zahlen müssen nicht mit deinen übereinstimmen):\n",
    "\n",
    "    Output:\n",
    "           Äpfel  Birnen  Bananen  Kartoffeln  Tomaten  Zitronen\n",
    "    Lidl    12.0    45.0      5.0        13.0      NaN       NaN\n",
    "    Netto   34.0    91.0      NaN         NaN     23.0      41.0\n",
    "    Rewe    15.0    16.0      2.0        17.0     24.0      35.0\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Äpfel  Birnen  Bananen  Kartoffeln  Tomaten  Zitronen\n",
      "Lidl    12.0    45.0      5.0        13.0      NaN       NaN\n",
      "Netto   34.0    91.0      NaN         NaN     23.0      41.0\n",
      "Rewe    15.0    16.0      2.0        17.0     24.0      35.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "    {\"Äpfel\": [12, 34, 15], \"Birnen\": [45,91,16]}, index=[\"Lidl\", \"Netto\", \"Rewe\"]\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\"Bananen\": [5,2,74], \"Kartoffeln\": [13,17,16]}, index=[\"Lidl\", \"Rewe\", \"Aldi\"]\n",
    ")\n",
    "\n",
    "df3 = pd.DataFrame(\n",
    "    {\"Tomaten\": [23,24,19], \"Zitronen\": [41,35,62]}, index=[\"Netto\", \"Rewe\", \"Aldi\"]\n",
    ")\n",
    "\n",
    "print(df1.join([df2,df3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "2. Erstelle zwei DataFrames mit Informationen zu Musikbands nach folgendem Schema:\n",
    "\n",
    "   1. Der erste df beinhaltet in einer Spalte vier Bandnamen und in einer weitere Spalte das Herkunftsland der Band.\n",
    "   2. Der zweite df beinhaltet in einer Spalte vier Bandnamen. Drei sollten identisch mit den Bands aus df1 sein, der vierte soll ein neuer Name sein. In einer weiteren Spalte steht das Genre der Band.\n",
    "\n",
    "Füge die beiden DataFrames anschließend anhand der Bandnamen zusammen, sodass du folgenden Output erhälst:\n",
    "\n",
    "    Output:\n",
    "             Band Land        Genre\n",
    "    0       Elvis  USA  Rock'n'Roll\n",
    "    1     Madonna  USA          Pop\n",
    "    2  Elton John   UK          Pop\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Band Land        Genre\n",
      "0       Elvis  USA  Rock'n'Roll\n",
      "1     Madonna  USA          Pop\n",
      "2  Elton John   UK          Pop\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {\n",
    "        \"Band\": [\"Elvis\", \"Madonna\", \"Elton John\", \"Beatles\"],\n",
    "        \"Land\": [\"USA\", \"USA\", \"UK\", \"UK\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        \"Band\": [\"Elvis\", \"Madonna\", \"Elton John\", \"Nirvana\"],\n",
    "        \"Genre\": [\"Rock'n'Roll\", \"Pop\", \"Pop\", \"Grunge\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "print(pd.merge(df1,df2,on=\"Band\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "3. Um welche Art von merge handelte es sich in der vorherigen Aufgabe? One to one, many to one oder many to many? Erläutere deine Antwort.\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# One to one, da EINE Zeile EINER anderen Zeile zugeordnet wurde."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "4. Gegeben sind die folgenden beiden DataFrames. Füge beide DataFrames so zusammen, dass die Mitarbeiter nach Abteilung sortiert aufgelistet werden. Der Output sollte folgendermaßen aussehen:\n",
    "\n",
    "    Output:\n",
    "       AbteilungsID Abteilungsname  ManagerID  MitarbeiterID     Name  Alter   Gehalt\n",
    "    0             1          Sales          5              1    Alice     25    50000\n",
    "    1             2      Marketing          3              5      Eve     45    70000\n",
    "    2             3    Engineering          3              2      Bob     30    55000\n",
    "    3             3    Engineering          3              3  Charlie     35    60000\n",
    "    4             4             HR          4              4   Debbie     40    65000\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AbteilungsID Abteilungsname  ManagerID  MitarbeiterID     Name  Alter  \\\n",
      "0             1          Sales          5              1    Alice     25   \n",
      "1             2      Marketing          3              5      Eve     45   \n",
      "2             3    Engineering          3              2      Bob     30   \n",
      "3             3    Engineering          3              3  Charlie     35   \n",
      "4             4             HR          4              4   Debbie     40   \n",
      "\n",
      "   Gehalt  \n",
      "0   50000  \n",
      "1   70000  \n",
      "2   55000  \n",
      "3   60000  \n",
      "4   65000  \n"
     ]
    }
   ],
   "source": [
    "mitarbeiter = pd.DataFrame({'MitarbeiterID': [1, 2, 3, 4, 5],\n",
    "                         'Name': ['Alice', 'Bob', 'Charlie', 'Debbie', 'Eve'],\n",
    "                         'Alter': [25, 30, 35, 40, 45],\n",
    "                         'Gehalt': [50000, 55000, 60000, 65000, 70000],\n",
    "                         'AbteilungsID': [1, 3, 3, 4, 2]})\n",
    "\n",
    "abteilungen = pd.DataFrame({'AbteilungsID': [1, 2, 3, 4],\n",
    "                            'Abteilungsname': ['Sales', 'Marketing', 'Engineering', 'HR'],\n",
    "                            'ManagerID': [5, 3, 3, 4]})\n",
    "\n",
    "\n",
    "mitarbeiter_abteilungen = pd.merge(abteilungen, mitarbeiter)\n",
    "print(mitarbeiter_abteilungen)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "5. Um welche Art von merge handelte es sich in Aufgabe 4? One to one, many to one oder many to many? Erläutere deine Antwort.\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Many to one, da MEHRERE Zeilen zu EINER Zeile zugeordnet wurden."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "6. Gegeben ist der folgende DataFrame. Kombiniere den DataFrame mitarbeiter, abteilungen und faehigkeiten so, dass du folgenden Output erhälst:\n",
    "\n",
    "    Output:\n",
    "       MitarbeiterID     Name  Alter  Gehalt  AbteilungsID Abteilungsname   ManagerID        Fähigkeiten\n",
    "    0              1    Alice     25   50000             1          Sales           5              Mathe\n",
    "    1              1    Alice     25   50000             1          Sales           5  Soziale Kompetenz\n",
    "    2              2      Bob     30   55000             3    Engineering           3             Python\n",
    "    3              2      Bob     30   55000             3    Engineering           3                C++\n",
    "    4              3  Charlie     35   60000             3    Engineering           3             Python\n",
    "    5              3  Charlie     35   60000             3    Engineering           3                C++\n",
    "    6              4   Debbie     40   65000             4             HR           4           Tabellen\n",
    "    7              4   Debbie     40   65000             4             HR           4            Planung\n",
    "    8              5      Eve     45   70000             2      Marketing           3             Design\n",
    "    9              5      Eve     45   70000             2      Marketing           3          Photoshop\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MitarbeiterID     Name  Alter  Gehalt  AbteilungsID Abteilungsname  \\\n",
      "0              1    Alice     25   50000             1          Sales   \n",
      "1              1    Alice     25   50000             1          Sales   \n",
      "2              2      Bob     30   55000             3    Engineering   \n",
      "3              2      Bob     30   55000             3    Engineering   \n",
      "4              3  Charlie     35   60000             3    Engineering   \n",
      "5              3  Charlie     35   60000             3    Engineering   \n",
      "6              4   Debbie     40   65000             4             HR   \n",
      "7              4   Debbie     40   65000             4             HR   \n",
      "8              5      Eve     45   70000             2      Marketing   \n",
      "9              5      Eve     45   70000             2      Marketing   \n",
      "\n",
      "   ManagerID        Fähigkeiten  \n",
      "0          5              Mathe  \n",
      "1          5  Soziale Kompetenz  \n",
      "2          3             Python  \n",
      "3          3                C++  \n",
      "4          3             Python  \n",
      "5          3                C++  \n",
      "6          4           Tabellen  \n",
      "7          4            Planung  \n",
      "8          3             Design  \n",
      "9          3          Photoshop  \n"
     ]
    }
   ],
   "source": [
    "faehigkeiten = pd.DataFrame({'AbteilungsID': [1, 1, 3, 3, 4, 4, 2, 2],\n",
    "                    'Fähigkeiten': ['Mathe', 'Soziale Kompetenz', 'Python', 'C++',\n",
    "                               'Tabellen', 'Planung', 'Design', 'Photoshop']})\n",
    "\n",
    "print(pd.merge(pd.merge(mitarbeiter, abteilungen), faehigkeiten))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "7. Um welche Art von merge handelte es sich in Aufgabe 4? One to one, many to one oder many to many? Erläutere deine Antwort.\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Many to many, da MEHRERE Zeilen zu MEHREREN Zeilen zugeordnet werden"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "8. Lade den penguins Datensatz und lass dir die Maximalwerte der verschiedenen Spalten ausgeben. Nutze dafür die Aggragtion Funktion.\n",
    "\n",
    "    Output:\n",
    "    species                 Gentoo\n",
    "    island               Torgersen\n",
    "    bill_length_mm            59.6\n",
    "    bill_depth_mm             21.5\n",
    "    flipper_length_mm        231.0\n",
    "    body_mass_g             6300.0\n",
    "    dtype: object\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species                 Gentoo\n",
      "island               Torgersen\n",
      "bill_length_mm            59.6\n",
      "bill_depth_mm             21.5\n",
      "flipper_length_mm        231.0\n",
      "body_mass_g             6300.0\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasca\\AppData\\Local\\Temp\\ipykernel_32312\\2589641575.py:4: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  print(pengu.agg(\"max\"))\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pengu = sns.load_dataset(\"penguins\")\n",
    "print(pengu.agg(\"max\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "9. Lass dir die Durchschnittswerte der verschiedenen Spalten des penguins Datensatzes ausgeben. Nutze dafür die Aggragtion Funktion.\n",
    "\n",
    "    Output:\n",
    "    bill_length_mm            43.921930\n",
    "    bill_depth_mm             17.151170\n",
    "    flipper_length_mm        200.915205\n",
    "    body_mass_g             4201.754386\n",
    "    dtype: float64\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bill_length_mm         43.921930\n",
      "bill_depth_mm          17.151170\n",
      "flipper_length_mm     200.915205\n",
      "body_mass_g          4201.754386\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasca\\AppData\\Local\\Temp\\ipykernel_32312\\238749623.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  print(pengu.agg(\"mean\"))\n"
     ]
    }
   ],
   "source": [
    "print(pengu.agg(\"mean\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "10. Gruppiere den penguins Datensatz nach der Spezies (\"species\") und lass dir die Minimalwerte der Spezies für die verschiedenen Eigenschaften ausgeben.\n",
    "\n",
    "    Output:\n",
    "               island  bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
    "    species\n",
    "    Adelie     Biscoe            32.1           15.5              172.0       2850.0\n",
    "    Chinstrap   Dream            40.9           16.4              178.0       2700.0\n",
    "    Gentoo     Biscoe            40.9           13.1              203.0       3950.0\n",
    "\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
      "species                                                               \n",
      "Adelie     Biscoe            32.1           15.5              172.0   \n",
      "Chinstrap   Dream            40.9           16.4              178.0   \n",
      "Gentoo     Biscoe            40.9           13.1              203.0   \n",
      "\n",
      "           body_mass_g  \n",
      "species                 \n",
      "Adelie          2850.0  \n",
      "Chinstrap       2700.0  \n",
      "Gentoo          3950.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasca\\AppData\\Local\\Temp\\ipykernel_32312\\3089327660.py:1: FutureWarning: Dropping invalid columns in DataFrameGroupBy.min is deprecated. In a future version, a TypeError will be raised. Before calling .min, select only columns which should be valid for the function.\n",
      "  print(pengu.groupby(\"species\").min())\n"
     ]
    }
   ],
   "source": [
    "print(pengu.groupby(\"species\").min())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<div  class=\"alert alert-block alert-info\">\n",
    "11. Gruppiere den penguins Datensatz nach der Spezies (\"species\") und der Insel (\"island\") und lass dir den Maximalwert der Spezies für die  Eigenschaft \"bill_length_mm\" ausgeben.\n",
    "\n",
    "    Output:\n",
    "    species    island\n",
    "    Adelie     Biscoe       45.6\n",
    "               Dream        44.1\n",
    "               Torgersen    46.0\n",
    "    Chinstrap  Dream        58.0\n",
    "    Gentoo     Biscoe       59.6\n",
    "    Name: bill_length_mm, dtype: float64\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pengu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mpengu\u001B[49m\u001B[38;5;241m.\u001B[39mgroupby([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecies\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124misland\u001B[39m\u001B[38;5;124m\"\u001B[39m])\u001B[38;5;241m.\u001B[39mmax()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbill_length_mm\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pengu' is not defined"
     ]
    }
   ],
   "source": [
    "print(pengu.groupby([\"species\", \"island\"]).max()[\"bill_length_mm\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
